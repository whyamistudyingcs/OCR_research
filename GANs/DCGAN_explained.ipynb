{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EduiYzyZHSF",
        "outputId": "60e4c947-709d-464b-fcc6-6507ae1c5949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "# manualSeed =  random.randint(1,1000) # use of you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input\n",
        "\n",
        "dataroot - the path to the root of the dataset folder. We will talk more about the dataset in the next section.\n",
        "\n",
        "workers - the number of worker threads for loading the data with the DataLoader.\n",
        "\n",
        "batch_size - the batch size used in training. The DCGAN paper uses a batch size of 128.\n",
        "\n",
        "image_size - the spatial size of the images used for training. This implementation defaults to 64x64. If another size is desired, the structures of D and G must be changed. See [here](https://github.com/pytorch/examples/issues/70) for more details.\n",
        "\n",
        "nc - number of color channels in the input images. For color images this is 3.\n",
        "\n",
        "nz - length of latent vector.\n",
        "\n",
        "ngf - relates to the depth of feature maps carried through the generator.\n",
        "\n",
        "ndf - sets the depth of feature maps propagated through the discriminator.\n",
        "\n",
        "num_epochs - number of training epochs to run. Training for longer will probably lead to better results but will also take much longer.\n",
        "\n",
        "lr - learning rate for training. As described in the DCGAN paper, this number should be 0.0002.\n",
        "\n",
        "beta1 - beta1 hyperparameter for Adam optimizers. As described in paper, this number should be 0.5.\n",
        "\n",
        "ngpu - number of GPUs available. If this is 0, code will run in CPU mode. If this number is greater than 0 it will run on that number of GPUs."
      ],
      "metadata": {
        "id": "lOF4kH10Z4GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root directory for dataset\n",
        "data_root = \"data/celeba\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "# size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input), specified in paper\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Learning rate for optimizers, specified in paper\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam optimizers, specified in paper\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPU available. Use 0 for CPU mode\n",
        "ngpu = 1"
      ],
      "metadata": {
        "id": "V3TtU3biZyEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "structure of data\n",
        "```\n",
        "data/celeba\n",
        "    -> img_align_celeba\n",
        "        -> 188242.jpg\n",
        "        -> 173822.jpg\n",
        "        -> 284702.jpg\n",
        "        -> 537394.jpg\n",
        "           ...\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_4qi_EfebLC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "dataset = dset.ImageFolder(root=data_root,\n",
        "                transform=transforms.Compose([\n",
        "                  transforms.Resize(image_size),\n",
        "                  transforms.CenterCrop(image_size),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                ]))\n",
        "\n",
        "# create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "\n",
        "# decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAHx3Mmrlxmy",
        "outputId": "e19729f7-94ab-46c2-d63a-59b31454de91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "FPtFW7N63U5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# According to paper, all weight has to be initialised to 0\n",
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    nn.init.constant_(m.bias.data, 0)\n"
      ],
      "metadata": {
        "id": "0IgqCnOJtcx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the output dimension for generator is\n",
        "\\begin{equation}\n",
        "H_{out}^{up}=s â‹…(H_{in}^{up}-1)+k-2p\n",
        "\\end{equation}\n",
        ",where s is stride, p is padding, and k is kernel size.\n",
        "Width can be computed in similar formula"
      ],
      "metadata": {
        "id": "9Zc-Y3dnjfgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downscale DCGAN for 1/2\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, ngpu):\n",
        "    super(Generator, self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "      # Input: N * z_dim * 1 * 1\n",
        "      self._block(nz, ngf * 8, 4, 1, 0), # C=64*8=512, H=W=k=4 => (N, 512, 4, 4)\n",
        "      self._block(ngf * 8, ngf * 4, 4, 2, 1), # C=64*4=256, H=W=2(4-1)+4-2*1=8 => (N, 256, 8, 8)\n",
        "      self._block(ngf * 4, ngf * 2, 4, 2, 1), # (N, 128, 16, 16)\n",
        "      self._block(ngf * 2, ngf, 4, 2, 1), # (N, 64, 32, 32)\n",
        "      nn.ConvTranspose2d(ngf, nc, 4, 2, 1), # (N, 3, 64, 64)\n",
        "      nn.Tanh() # normalize the value in between -1 and 1\n",
        "    )\n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "      nn.ConvTranspose2d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        bias=False,\n",
        "      ),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(True)\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "JfNdWA8rxF_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the ``weights_init`` function to randomly initialize all weights\n",
        "#  to ``mean=0``, ``stdev=0.02``.\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ],
      "metadata": {
        "id": "2FwZ-PsUl-PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the output dimension for discriminator is\n",
        "\\begin{equation}\n",
        "H_{out}=\\frac{(H_{in}-k+2p)}{s}+1\n",
        "\\end{equation}\n",
        ",where s is stride, p is padding, and k is kernel size.\n",
        "Width can be computed in similar formula"
      ],
      "metadata": {
        "id": "vk0_6gXOsviV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, ngpu):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.ngpu = ngpu\n",
        "    self.main = nn.Sequential(\n",
        "      # input: nc * 64, 64\n",
        "      nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), # ndf * 32 * 32\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "      self._block(ndf, ndf*2, 4, 2, 1), # (128, 16, 16)\n",
        "      self._block(ndf*2, ndf*4, 4, 2, 1), # (256, 8, 8)\n",
        "      self._block(ndf*4, ndf*8, 4, 2, 1), # (512, 4, 4)\n",
        "\n",
        "      nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False), # (1, 1, 1)\n",
        "      nn.Sigmoid() # classifier\n",
        "    )\n",
        "\n",
        "  def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(\n",
        "        in_channels=in_channels,\n",
        "        out_channels=out_channels,\n",
        "        kernel_size=kernel_size,\n",
        "        stride=stride,\n",
        "        padding=padding,\n",
        "        bias=False,\n",
        "      ),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "TAEHa4lXpXX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the ``weights_init`` function to randomly initialize all weights\n",
        "# like this: ``to mean=0, stdev=0.2``.\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ],
      "metadata": {
        "id": "pg3TMsSHss-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Recall the objective of GAN is\n",
        "\\begin{equation}\n",
        "\\min_{G}\\max_{D}V(D,G)=E_{x\\sim P_{data}}[log(D(x))]+E_{x\\sim P_{g}}[log(1-D(x))]\n",
        "\\end{equation}\n",
        "we will use the Binary Cross Entropy loss\n",
        "\\begin{equation}\n",
        "l(x,y) =L=[l_1,\\cdots,1_N],l_i=-[y_i\\cdot \\log x_i+(1-y_i)\\cdot \\log (1-x_i)]\n",
        "\\end{equation}\n",
        "\n",
        "It is important to understand how we can choose which component we wish to calculate just by changing y. We set y = 1 and x = D(x) when training discriminator, and set y = 0 and x = D(G(z)) when training generator.\n",
        "\n",
        "In practice, minimizing over G on log(1-D(G(z))) is hard to train due to its flat gradient at first. Therefore, we will replace it by minimizing over G on -log(D(G(z))). In other word,we wish to maximize over G on log(D(G(z))). In the code we accomplish this by: classifying the Generator output from part 1 with the discriminator, computing G; loss using real labels as GT, computing G's gradients in the backward pass, and finally updatiing G's parameters with an optimizer step.  It may seem counter-intuitive to use the real labels as GT labels for the loss function, but this allows us to use the log(x) part of the BCELoss (rather than the log(1âˆ’x) part) which is exactly what we want.Search vanishing gradient on GAN to know more if you are interested.\n",
        "\n",
        "As specified in the DCGAN paper, both optimizers of G and D are Adam optimizers with lr=0.0002 and Beta1=0.5.\n",
        "\n",
        "In the training loop, we will periodically input Gaussian distribution fixed_noise into\n",
        "G, and over the iterations we will see images form out of the noise."
      ],
      "metadata": {
        "id": "CSVdain3viFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "# create batch of latent vectors that we will use to visualize\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "aiRWKwkiuxjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "# lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training loop...\")\n",
        "# for each epoch\n",
        "for epoch in range(num_epochs):\n",
        "  # for each batch in the dataloader\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "    '''\n",
        "    (1) update D net: maximize log(D(x)) + log(1-D(G(z)))\n",
        "    '''\n",
        "    # Train with all-real batch\n",
        "    netD.zero_grad()\n",
        "    # format batch\n",
        "    real_cpu = data[0].to(device)\n",
        "    b_size = real_cpu.size(0)\n",
        "    label = torch.fill((b_size,), real_label, dtype=torch.float, device=device)\n",
        "    # forward pass real batch through D\n",
        "    output = netD(real_cpu).view(-1)\n",
        "    # Calculate loss on all-real batch\n",
        "    errD_real = criterion(output, label)\n",
        "    # Calculate gradients for D in backward pass\n",
        "    errD_real.backward()\n",
        "    D_x = output.mean().item()\n",
        "\n",
        "    # Train with all-fake batch\n",
        "    noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "    # Generate fake image batch with G\n",
        "    fake = netG(noise)\n",
        "    label.fill_(fake_label)\n",
        "    # Classify all fake batch with D\n",
        "    # detach fake batch from computational graph as we do not require gradient from G net\n",
        "    output = netD(fake.detach()).view(-1)\n",
        "    # Calculate D's loss on the all-fake batch\n",
        "    errD_fake = criterion(output, label)\n",
        "    # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "    errD_fake.backward()\n",
        "    D_G_z1 = output.mean().item()\n",
        "    # Compute error of D as sum over the fake and the real batches\n",
        "    errD = errD_real + errD_fake\n",
        "    # Update D\n",
        "    optimizerD.step()\n",
        "\n",
        "\n",
        "    '''\n",
        "    (2) Update G network: maximize log(D(G(z)))\n",
        "    '''\n",
        "    netG.zero_grad()\n",
        "    # fake labels are real for generator cost\n",
        "    label.fill_(real_label)\n",
        "    # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "    output = netD(fake).view(-1)\n",
        "    # Calculate G's loss\n",
        "    errG = criterion(output, label)\n",
        "    # Calculate gradients for G\n",
        "    errG.backward()\n",
        "    D_G_z2 = output.mean().item()\n",
        "    # Update G\n",
        "    optimizerG.step()\n",
        "\n",
        "    # Output training stats\n",
        "    # Format: [epoch/num_epochs][batch_id/len_dataset]   Loss_D: errD.item()  Loss_G: errG.item()  D(x): D_x  D(G(z)): z1 / z2\n",
        "    if i % 50 == 0:\n",
        "      print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "      % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "    # Save Losses for plotting later\n",
        "    G_losses.append(errG.item())\n",
        "    D_losses.append(errD.item())\n",
        "\n",
        "    # Check how the generator is doing by saving G's output on fixed_noise\n",
        "    if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "      with torch.no_grad():\n",
        "        fake = netG(fixed_noise).detach().cpu()\n",
        "      img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "    iters += 1"
      ],
      "metadata": {
        "id": "szKEo3Bn4mN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "1uL2dULUMJjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1YvlGQj2HNTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "id": "ZNVRSIM5xAXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z6UuoZusPUL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}